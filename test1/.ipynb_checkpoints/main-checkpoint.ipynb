{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e1cead45cfb09c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "   ### Load the package"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dccc255f8bc0d0a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T03:08:26.354939Z",
     "start_time": "2024-04-01T03:08:25.085484Z"
    }
   },
   "id": "a51fee8a344fd651",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Config for training time"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ae97c8ea74f5d3a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-01T02:46:58.449734Z",
     "start_time": "2024-04-01T02:46:58.392010Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "# configration of the model\n",
    "config = {\n",
    "    'seed': 5201314,      # Your seed number, you can pick your lucky number. :)\n",
    "    'select_all': True,   # Whether to use all features.\n",
    "    'valid_ratio': 0.2,   # validation_size = train_size * valid_ratio\n",
    "    'n_epochs': 300,     # Number of epochs.\n",
    "    'n_classes': 3,\n",
    "    'train_root':  './dataset/train/',\n",
    "    'valild_root': './dataset/val/',\n",
    "    'base_channels': 3,\n",
    "    'input_channels': 1,\n",
    "    'input_shape': (1, 1, 150, 150),\n",
    "    'depth': 4,\n",
    "    'block_type': 'basic',\n",
    "    'batch_size': 256,\n",
    "    'learning_rate': 1e-3,\n",
    "    'early_stop': 400,    # If model has not improved for this many consecutive epochs, stop training.\n",
    "    'save_path': './models/model.ckpt'  # Your model will be saved here.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define the model net"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d440288f1f78201b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# model\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, bias=False, padding='same')\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, bias=False, padding='same')\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut.add_module('conv', nn.Conv2d(in_channels, out_channels, 1, bias=False, padding='same'))\n",
    "            self.shortcut.add_module('bn', nn.BatchNorm2d(out_channels))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        y = F.relu(self.bn2(self.conv2(y)), inplace=True)\n",
    "        y = y + self.shortcut(x)\n",
    "        y = F.relu(y, inplace=True)\n",
    "        return y\n",
    "\n",
    "\n",
    "class EPNet(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(EPNet, self).__init__()\n",
    "        shape = config['input_shape']\n",
    "        input_channel = config['input_channels']\n",
    "        self.conv = nn.Conv2d(input_channel, 4, 5, padding='same')\n",
    "        self.stage1 = BasicBlock(4, 8)\n",
    "        self.stage2 = BasicBlock(8, 24)\n",
    "        self.stage3 = BasicBlock(24, 32)\n",
    "        self.stage4 = BasicBlock(32, 64)\n",
    "        with torch.no_grad():\n",
    "            self.feature = self._forward_test(torch.zeros(shape)).view(-1).shape[0]\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.feature, config['n_classes']),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def _forward_test(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "\n",
    "        x = F.adaptive_avg_pool2d(x, output_size=1)\n",
    "        # print(\"average pool:\", x.shape)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_test(x)\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T02:47:00.172863Z",
     "start_time": "2024-04-01T02:47:00.166924Z"
    }
   },
   "id": "19f833b336375fe9",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### define dataloader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d600258aeb2a29e3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 root: str,\n",
    "                 # istrain: bool,\n",
    "                 # data_size: int,\n",
    "                 return_index: bool = False):\n",
    "        # notice that:\n",
    "        # sub_data_size mean sub-image's width and height.\n",
    "        \"\"\" basic information \"\"\"\n",
    "        self.root = root\n",
    "        # self.data_size = data_size\n",
    "        self.return_index = return_index\n",
    "        # self.istrain = istrain\n",
    "\n",
    "        \"\"\" declare data augmentation \"\"\"\n",
    "        # normalize = transforms.Normalize(\n",
    "        #             mean=[0.485, 0.456, 0.406],\n",
    "        #             std=[0.229, 0.224, 0.225]\n",
    "        #         )\n",
    "        # \n",
    "        # 448:600\n",
    "        # 384:510\n",
    "        # 768:\n",
    "        # if istrain:\n",
    "        #     # transforms.RandomApply([RandAugment(n=2, m=3, img_size=data_size)], p=0.1)\n",
    "        #     # RandAugment(n=2, m=3, img_size=sub_data_size)\n",
    "        #     self.transforms = transforms.Compose([\n",
    "        #                 transforms.Resize((510, 510), Image.BILINEAR),\n",
    "        #                 transforms.RandomCrop((data_size, data_size)),\n",
    "        #                 transforms.RandomHorizontalFlip(),\n",
    "        #                 transforms.RandomApply([transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 5))], p=0.1),\n",
    "        #                 transforms.RandomAdjustSharpness(sharpness_factor=1.5, p=0.1),\n",
    "        #                 transforms.ToTensor(),\n",
    "        #                 normalize\n",
    "        #         ])\n",
    "        # else:\n",
    "        #     self.transforms = transforms.Compose([\n",
    "        #                 transforms.Resize((510, 510), Image.BILINEAR),\n",
    "        #                 transforms.CenterCrop((data_size, data_size)),\n",
    "        #                 transforms.ToTensor(),\n",
    "        #                 normalize\n",
    "        #         ])\n",
    "\n",
    "        \"\"\" read all data information \"\"\"\n",
    "        self.data_infos = self.getDataInfo(root)\n",
    "        # print(self.data_infos)\n",
    "\n",
    "\n",
    "    def getDataInfo(self, root):\n",
    "        data_infos = []\n",
    "        folders = os.listdir(root)\n",
    "        folders.sort() # sort by alphabet\n",
    "        # print(\"[dataset] class number:\", len(folders))\n",
    "        eye = np.eye(len(folders), dtype=np.float32)\n",
    "        for class_id, folder in enumerate(folders):\n",
    "            files = os.listdir(root+folder)\n",
    "            class_files = root + folder\n",
    "            for file in files:\n",
    "                data_path = class_files+\"/\"+file\n",
    "                data_infos.append({\"path\":data_path, \"label\":eye[class_id]})\n",
    "        return data_infos\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_infos)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # get data information.\n",
    "        image_path = self.data_infos[index][\"path\"]\n",
    "        label = self.data_infos[index][\"label\"]\n",
    "        # read image by opencv.\n",
    "        # print(\"istrain: \", self.istrain)\n",
    "        # img = cv2.imread(image_path)\n",
    "        # print(\"DEBUG:\", img.shape)\n",
    "        # img = img[:, :, ::-1] # BGR to RGB.\n",
    "        # print(\"RGB:  \", img.shape)\n",
    "\n",
    "        # to PIL.Image\n",
    "        # img = Image.fromarray(img)\n",
    "        img = np.load(image_path).astype(np.float32)\n",
    "        # print(img.shape)\n",
    "        # print(\"befortransforms:  \", img.size)\n",
    "        # img = self.transforms(img)\n",
    "        # print(\"after transforms: \", img.shape)\n",
    "\n",
    "        # istrain:  True\n",
    "        # DEBUG: (354, 500, 3)\n",
    "        # RGB:   (354, 500, 3)\n",
    "        # befortransforms:   (500, 354)\n",
    "        # after transforms:  torch.Size([3, 384, 384])\n",
    "\n",
    "        if self.return_index:\n",
    "            # return index, img, sub_imgs, label, sub_boundarys\n",
    "            return index, img, label\n",
    "\n",
    "        # return img, sub_imgs, label, sub_boundarys\n",
    "        return img, label\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T02:47:01.335306Z",
     "start_time": "2024-04-01T02:47:01.330567Z"
    }
   },
   "id": "fe651d4cbafc0427",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from data import ImageDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# def download(url, dir: str, filename: str):\n",
    "#\n",
    "#     if not os.path.exists(dir):\n",
    "#         os.mkdir(dir)\n",
    "#\n",
    "#\n",
    "#     if filename not in os.listdir(dir):\n",
    "#         urllib.request.urlretrieve(url, dir+filename)\n",
    "\n",
    "def build_loader(config):\n",
    "    train_set, train_loader = None, None\n",
    "    if config['train_root'] is not None:\n",
    "        train_set = ImageDataset(root=config['train_root'], return_index=False)\n",
    "        train_loader = DataLoader(train_set, shuffle=True, batch_size=config['batch_size'])\n",
    "\n",
    "    val_set, val_loader = None, None\n",
    "    if config['valild_root'] is not None:\n",
    "        val_set = ImageDataset(root=config['valild_root'], return_index=False)\n",
    "        val_loader = DataLoader(val_set, shuffle=True, batch_size=config['batch_size'])\n",
    "        # only give the number of batch size data\n",
    "\n",
    "    return train_loader, val_loader\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T02:47:01.942117Z",
     "start_time": "2024-04-01T02:47:01.938038Z"
    }
   },
   "id": "7e415394b63f4a1d",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "### define the training function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca4db5de85883802"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Train\n",
    "# model = test()\n",
    "def train(model, train_loader, valid_loader, config, device):\n",
    "    # ll = nn.MSELoss()\n",
    "    ll = nn.CrossEntropyLoss()\n",
    "\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.003, momentum=0.8)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=1e-5)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=300)\n",
    "\n",
    "    writer = SummaryWriter() # Writer of tensorboard.\n",
    "    if not os.path.isdir('./models'):\n",
    "        os.mkdir('./models')\n",
    "\n",
    "    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train() # Set your model to train mode.\n",
    "        model.to(device)\n",
    "        loss_record = []\n",
    "\n",
    "        # tqdm is a package to visualize your training progress.\n",
    "        train_pbar = tqdm(train_loader, position=0, leave=True)\n",
    "\n",
    "        for x, y in train_pbar:\n",
    "            optimizer.zero_grad()               # Set gradient to zero.\n",
    "            x, y = x.to(device), y.to(device)   # Move your data to device.\n",
    "            pred = model(x)\n",
    "            loss = ll(pred, y)\n",
    "            # print(\"pred argmax:\", torch.sum(torch.argmax(pred, dim=1) == torch.argmax(y, dim=1)))\n",
    "\n",
    "            loss.backward()                     # Compute gradient(backpropagation).\n",
    "            optimizer.step()                    # Update parameters.\n",
    "\n",
    "            step += 1\n",
    "            loss_record.append(loss.detach().item())\n",
    "\n",
    "            # Display current epoch number and loss on tqdm progress bar.\n",
    "            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
    "            train_pbar.set_postfix({'loss': loss.detach().item(),\n",
    "                                    'lr':   optimizer.state_dict()['param_groups'][0]['lr']\n",
    "                                    })\n",
    "\n",
    "        mean_train_loss = sum(loss_record)/len(loss_record)\n",
    "\n",
    "        writer.add_scalar('Loss/train', mean_train_loss, step)\n",
    "        lr_scheduler.step()\n",
    "\n",
    "\n",
    "        #####################\n",
    "\n",
    "        # Valid\n",
    "\n",
    "        #####################\n",
    "        model.eval() # Set your model to evaluation mode.\n",
    "\n",
    "\n",
    "        right = []\n",
    "        loss_record = []\n",
    "        for x, y in valid_loader:\n",
    "\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                # print(f'pred.shape = {pred.shape} y.shape = {y.shape}')\n",
    "                loss = ll(pred, y)\n",
    "            right.append(torch.sum(torch.argmax(pred, dim=1) == torch.argmax(y, dim=1)))\n",
    "\n",
    "            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
    "            train_pbar.set_postfix({'acc': right[-1]/config['batch_size']})\n",
    "\n",
    "\n",
    "            loss_record.append(loss.item())\n",
    "\n",
    "        mean_valid_acc = sum(right) / (len(right) * config['batch_size'])\n",
    "        mean_valid_loss = sum(loss_record)/len(loss_record)\n",
    "        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}, Accary: {mean_valid_acc:4f}%')\n",
    "\n",
    "        writer.add_scalar('Acc/valid', mean_valid_acc, step)\n",
    "        writer.add_scalar('Loss/valid', mean_valid_loss, step)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if mean_valid_loss < best_loss:\n",
    "            best_loss = mean_valid_loss\n",
    "            torch.save(model.state_dict(), config['save_path']) # Save your best model\n",
    "            print('Saving model with loss {:.3f}...'.format(best_loss))\n",
    "            early_stop_count = 0\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "\n",
    "        if early_stop_count >= config['early_stop']:\n",
    "            print('\\nModel is not improving, so we halt the training session.')\n",
    "            return\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T02:47:02.880273Z",
     "start_time": "2024-04-01T02:47:02.873668Z"
    }
   },
   "id": "5bb8fc3754b0a251",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load dataset and create the net"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b9fe7aa10a34b06"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_loader, valid_loader = build_loader(config)\n",
    "\n",
    "model = EPNet(config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T02:47:58.899961Z",
     "start_time": "2024-04-01T02:47:58.284624Z"
    }
   },
   "id": "892139f50b44d991",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "### begin to train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fabf92b454c83210"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: I am trianing on the server 3090 24GB\n",
    "train(model, train_loader, valid_loader, config, device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "214f1a6a230a973f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Display the training time loss and acc"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b67299ecc92d8b95"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mrun tendorboard.....\u001B[m\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-d4df01c2a5c935ca\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-d4df01c2a5c935ca\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('\\x1b[31mrun tendorboard.....\\033[m')\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=./runs/"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T03:08:32.021319Z",
     "start_time": "2024-04-01T03:08:29.484444Z"
    }
   },
   "id": "5dbd61d5c2aaf106",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4adb4a910899784b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
